{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load & Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”— ëŒ€ìš©ëŸ‰ íŒŒì¼ ìë™ ë‹¤ìš´ë¡œë“œ\n",
    "import gdown\n",
    "import os\n",
    "\n",
    "# íŒŒì¼ ID ì„¤ì • (Google Drive ê³µê°œ ë§í¬ì—ì„œ ì¶”ì¶œ)\n",
    "TRAIN_FILE_ID = \"1teA9GmYlIsutaDLWvCCsLeh7833t-TC_\"\n",
    "TEST_FILE_ID = \"1bGC_YWtNUOroHARfmzCjrL8oPcvb7Tpw\"\n",
    "SAMPLE_FILE_ID = \"1ebrHVj-CtM-7aEz4OqP-bCHlazle-PKM\"\n",
    "\n",
    "def download_from_drive(file_id, filename):\n",
    "    if file_id and not os.path.exists(filename):\n",
    "        url = f'https://drive.google.com/uc?id={file_id}'\n",
    "        print(f\"ğŸ“¥ {filename} ë‹¤ìš´ë¡œë“œ ì¤‘...\")\n",
    "        gdown.download(url, filename, quiet=False)\n",
    "        print(f\"âœ… {filename} ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!\")\n",
    "    elif os.path.exists(filename):\n",
    "        print(f\"âœ… {filename} ì´ë¯¸ ì¡´ì¬í•¨\")\n",
    "\n",
    "# ìë™ ë‹¤ìš´ë¡œë“œ ì‹¤í–‰\n",
    "download_from_drive(TRAIN_FILE_ID, 'train.csv')\n",
    "download_from_drive(TEST_FILE_ID, 'test.csv')\n",
    "download_from_drive(SAMPLE_FILE_ID, 'sample_submission.csv')\n",
    "\n",
    "# CSV íŒŒì¼ ì½ê¸°\n",
    "train = pd.read_csv('./train.csv', encoding='utf-8-sig')\n",
    "test = pd.read_csv('./test.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[['title', 'full_text']]\n",
    "y = train['generated']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF ë²¡í„°í™”\n",
    "get_title = FunctionTransformer(lambda x: x['title'], validate=False)\n",
    "get_text = FunctionTransformer(lambda x: x['full_text'], validate=False)\n",
    "\n",
    "vectorizer = FeatureUnion([\n",
    "    ('title', Pipeline([('selector', get_title),\n",
    "                        ('tfidf', TfidfVectorizer(ngram_range=(1,2), max_features=3000))])),\n",
    "    ('full_text', Pipeline([('selector', get_text), \n",
    "                            ('tfidf', TfidfVectorizer(ngram_range=(1,2), max_features=10000))])),\n",
    "])\n",
    "\n",
    "# í”¼ì²˜ ë³€í™˜\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_val_vec = vectorizer.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸ ì •ì˜\n",
    "xgb = XGBClassifier(random_state=42)\n",
    "xgb.fit(X_train_vec, y_train)\n",
    "\n",
    "val_probs = xgb.predict_proba(X_val_vec)[:, 1]\n",
    "auc = roc_auc_score(y_val, val_probs)\n",
    "print(f\"Validation AUC: {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testìš©ìœ¼ë¡œ 'paragraph_text'ë¥¼ 'full_text'ì— ë§ê²Œ ì¬ëª…ëª…\n",
    "test = test.rename(columns={'paragraph_text': 'full_text'})\n",
    "X_test = test[['title', 'full_text']]\n",
    "\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "probs = xgb.predict_proba(X_test_vec)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('./sample_submission.csv', encoding='utf-8-sig')\n",
    "sample_submission['generated'] = probs\n",
    "\n",
    "sample_submission.to_csv('./baseline_submission.csv', index=False)\n",
    "\n",
    "# íŒŒì¼ ë‹¤ìš´ë¡œë“œ (ì½”ë©ì—ì„œ)\n",
    "try:\n",
    "    from google.colab import files\n",
    "    files.download('baseline_submission.csv')\n",
    "    print(f\"âœ… íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹œì‘: baseline_submission.csv\")\n",
    "except ImportError:\n",
    "    print(\"ë¡œì»¬ í™˜ê²½ì—ì„œ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤. íŒŒì¼ì´ í˜„ì¬ ë””ë ‰í„°ë¦¬ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
